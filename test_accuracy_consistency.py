"""
Test Accuracy Consistency Across All Pages
Verifies that all model accuracy values are consistent
"""

import sys
from model_config import MODEL_PERFORMANCE, get_all_models, get_best_model

print("="*70)
print("üß™ TESTING ACCURACY CONSISTENCY")
print("="*70)

# Test 1: Central Config
print("\nüìä Test 1: Central Configuration (model_config.py)")
print("-" * 70)

expected_accuracies = {
    'deep_learning': 88.9,
    'random_forest': 85.3,
    'logistic_regression': 78.0,
    'gradient_boosting': 74.2
}

all_pass = True
for model_key, expected_acc in expected_accuracies.items():
    actual_acc = MODEL_PERFORMANCE[model_key]['accuracy']
    status = "‚úÖ" if actual_acc == expected_acc else "‚ùå"
    print(f"{status} {MODEL_PERFORMANCE[model_key]['name']}: {actual_acc}% (expected: {expected_acc}%)")
    if actual_acc != expected_acc:
        all_pass = False

if all_pass:
    print("\n‚úÖ All accuracies in central config are correct!")
else:
    print("\n‚ùå Some accuracies don't match expected values!")
    sys.exit(1)

# Test 2: Best Model
print("\nüèÜ Test 2: Best Model Detection")
print("-" * 70)

best_key, best_model = get_best_model()
print(f"Best Model: {best_model['name']}")
print(f"Accuracy: {best_model['accuracy']}%")
print(f"AUC-ROC: {best_model['auc_roc']}")

if best_key == 'deep_learning' and best_model['accuracy'] == 88.9:
    print("‚úÖ Best model correctly identified!")
else:
    print("‚ùå Best model detection failed!")
    sys.exit(1)

# Test 3: Model Order
print("\nüìã Test 3: Model Display Order")
print("-" * 70)

all_models = get_all_models()
print("Display order:")
for idx, (key, model) in enumerate(all_models.items(), 1):
    icon = "üèÜ" if idx == 1 else "‚≠ê" if idx == 2 else "  "
    print(f"{icon} {idx}. {model['name']}: {model['accuracy']}%")

# Test 4: API Simulation
print("\nüîå Test 4: API Response Simulation")
print("-" * 70)

# Simulate what API would return
api_response = {
    'success': True,
    'models': {},
    'total': len(MODEL_PERFORMANCE)
}

for key, model in MODEL_PERFORMANCE.items():
    api_response['models'][key] = {
        **model,
        'loaded': True,
        'available': True
    }

print(f"Total models: {api_response['total']}")
print(f"Models in response: {list(api_response['models'].keys())}")

for key, model in api_response['models'].items():
    print(f"  ‚Ä¢ {model['icon']} {model['name']}: {model['accuracy']}%")

print("\n‚úÖ API response structure is correct!")

# Test 5: Consistency Check
print("\nüîç Test 5: Cross-Model Consistency")
print("-" * 70)

# Check that all models have required fields
required_fields = ['name', 'accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'icon', 'category']

for key, model in MODEL_PERFORMANCE.items():
    missing_fields = [field for field in required_fields if field not in model]
    if missing_fields:
        print(f"‚ùå {model['name']} missing fields: {missing_fields}")
        all_pass = False
    else:
        print(f"‚úÖ {model['name']}: All required fields present")

# Test 6: Accuracy Range Validation
print("\nüìè Test 6: Accuracy Range Validation")
print("-" * 70)

for key, model in MODEL_PERFORMANCE.items():
    acc = model['accuracy']
    if 0 <= acc <= 100:
        print(f"‚úÖ {model['name']}: {acc}% (valid range)")
    else:
        print(f"‚ùå {model['name']}: {acc}% (invalid range!)")
        all_pass = False

# Test 7: Best Model Verification
print("\nüéØ Test 7: Best Model Verification")
print("-" * 70)

sorted_models = sorted(MODEL_PERFORMANCE.items(), key=lambda x: x[1]['accuracy'], reverse=True)
best = sorted_models[0]

print(f"Highest accuracy: {best[1]['name']} ({best[1]['accuracy']}%)")
print(f"Expected: Enhanced Multimodal (88.9%)")

if best[0] == 'deep_learning' and best[1]['accuracy'] == 88.9:
    print("‚úÖ Best model verification passed!")
else:
    print("‚ùå Best model verification failed!")
    all_pass = False

# Final Summary
print("\n" + "="*70)
print("üìã CONSISTENCY TEST SUMMARY")
print("="*70)

print("\n‚úÖ Verified Accuracy Values:")
print(f"   üèÜ Enhanced Multimodal: {MODEL_PERFORMANCE['deep_learning']['accuracy']}%")
print(f"   ‚≠ê Random Forest: {MODEL_PERFORMANCE['random_forest']['accuracy']}%")
print(f"   üìä Logistic Regression: {MODEL_PERFORMANCE['logistic_regression']['accuracy']}%")
print(f"   ‚ö° Gradient Boosting: {MODEL_PERFORMANCE['gradient_boosting']['accuracy']}%")

print("\n‚úÖ All Tests Passed!")
print("\nüìù Next Steps:")
print("   1. Start Flask app: python app.py")
print("   2. Test API: curl http://localhost:5000/api/available-models")
print("   3. Check frontend pages:")
print("      ‚Ä¢ /predict")
print("      ‚Ä¢ /predict-enhanced")
print("      ‚Ä¢ /dashboard")
print("   4. Verify all pages show same accuracy values")

print("\n" + "="*70)
print("‚úÖ ACCURACY CONSISTENCY TEST COMPLETE!")
print("="*70)
